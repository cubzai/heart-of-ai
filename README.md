# HEART of AI

**Status:** Active Development
**Full name:** Hierarchical Epistemic Architecture for Reasoning and Truth-seeking (HEART)

Code and models from the research paper:

> **"HEART: Hierarchical Epistemic Architecture for Reasoning and Truth-seeking"**
> by **CubzAI**

ðŸ“„ Read the full paper: [`assets/ALHAMDULILLAH_Heart_of_AI.pdf`](heart-of-ai/assets/ALHAMDULILLAH_Heart_of_AI.pdf)

---

## 1. Overview

HEART is a unified framework that wraps a base language model (GPTâ€‘2 in this implementation) with hierarchical control and explicit epistemic behavior. It addresses four core limitations of contemporary LLMs:

1. **Hallucination Generation**
   Confident but false statements in high-stakes domains (medical, legal, financial, etc.).

2. **Limited Reasoning Depth**
   Fixed transformer depth tends to restrict effective reasoning to ~5â€“10 semantic steps.

3. **Parameter Inefficiency**
   Naively scaling to billions of parameters is expensive and hard to deploy.

4. **Static Epistemic Behavior**
   Standard LLMs lack principled mechanisms to abstain, retrieve, or self-correct.

### 1.1 Key Innovations

HEART integrates:

- **Hierarchical Recursion (L/H Modules)**
  Multi-timescale latent modules (L and H) achieving *effective* depths up to 84+ layers without backpropagating through the entire depth.

- **Learned Epistemic Validator**
  A policy head that selects discrete actions: **accept / abstain / retrieve / repair**, conditioned on token- and concept-level signals.

- **Parameter-Efficient Adaptation**
  Only a small wrapper (Lâ€‘module, Hâ€‘module, validator) is trained, achieving up to **99.98% trainable parameter reduction** vs. large LLM baselines.

- **Continual Learning at Inference (HEARTâ€‘CL)**
  Optional online adaptation loop that uses epistemic signals and feedback to update the wrapper safely.

---

## 2. Architecture Overview

![Architecture](heart-of-ai/assets/heart-of-ai.png)

### 2.1 How GPTâ€‘2 is Modified by HEART

Standard GPTâ€‘2:

> Flat, sequential transformer with fixed depth, generating tokens autoregressively.

HEART wraps GPTâ€‘2 with three additional components:

1. **Lâ€‘Module (Latent Reasoner)**
2. **Hâ€‘Module (Semantic Controller)**
3. **Epistemic Validator (Action Policy)**

Together, they turn GPTâ€‘2 into a *hierarchical, epistemically-aware* system.

---

### 2.2 Lâ€‘Module (Latent Reasoner)

**Purpose:** Fast, high-frequency reasoning within *supervision segments*.

**Update equation:**
```text
h_L(t) = f_L(h_L(t-1), h_H(c), Ï†(x, yâ‚:â‚œâ‚‹â‚))
```

- Runs at every step (t) inside a segment.
- Combines:
  - Previous Lâ€‘state (`h_L(t-1)`) â€” local continuity.
  - Current Hâ€‘state (`h_H(c)`) â€” global semantic guidance.
  - Base LM features (`Ï†(Â·)` from GPTâ€‘2) â€” lexical/semantic grounding.
- Implemented as a small GRU/attention module (e.g., 256â€‘dim vs 768+ in GPTâ€‘2).
- Converges within a segment to a stable representation.

**Benefits:**

- Enables local reasoning refinement without deep backprop through the full transformer stack.
- Keeps segment-effective depth modest (e.g., 12â€“18) to avoid vanishing gradients.

---

### 2.3 Hâ€‘Module (Semantic Controller)

**Purpose:** Slow, low-frequency controller across segments.

**Update equation:**
```text
h_H(c+1) = f_H(h_H(c), hÌƒ_L(c))
```

- Updates at segment boundaries (e.g., every 4â€“6 steps).
- Receives the **converged** Lâ€‘state `hÌƒ_L(c)` (not noisy per-step states).
- Maintains global semantic context and long-range structure.
- Uses a moderate state size (e.g., 512â€‘dim).

**Benefits:**

- Provides stable guidance across longer reasoning chains.
- Avoids collapse seen in monolithic deep transformers.
- Enables *effective* depth scaling via multi-scale recursion.

---

### 2.4 Epistemic Validator

**Purpose:** Learn a **policy** over four epistemic actions to control reliability.

**Inputs:**

- **Token-Level:**
  - GPTâ€‘2 logits
  - Hidden states and attention patterns

- **Concept-Level:**
  - Sparse autoencoder (SAE) features
  - Summaries of L/H states

- **Alignment Signals:**
  - Plan vs realization consistency
  - LMâ€‘vsâ€‘retrievedâ€‘context agreement

**Outputs:**

```text
(Î±â‚œ, Ï€â‚œ) = f_v(zâ‚œ)
```

- **Î±â‚œ âˆˆ [0, 1]**: Alignment / confidence score.
- **Ï€â‚œ(a | zâ‚œ)**: Policy distribution over actions `a âˆˆ {accept, abstain, retrieve, repair}`.

#### 2.4.1 Four Epistemic Actions

1. **Accept**
   - Continue generation; commit next token(s) to output.
   - Default path when alignment is high.

2. **Abstain**
   - Halt generation; return an explicit uncertainty statement.
   - Crucial for safety-critical or knowledge-scarce regions.

3. **Retrieve**
   - Trigger targeted RAG (retrieval-augmented generation).
   - Retrieve external knowledge only when confidence drops.
   - Merge retrieved context into subsequent segment inputs.

4. **Repair**
   - Initiate self-correction:
     - Locate likely error span (via attention / SAE features).
     - Update L/H states.
     - Re-generate from a checkpointed point.
     - Re-validate; repeat up to K iterations (typically 2â€“3).

**Training:**

- Supervised action labels (multi-task):
  - **Alignment loss**: MSE between Î±â‚œ and empirical correctness.
  - **Epistemic classification loss**: Cross-entropy on action labels.
- End-to-end gradients through validator and wrapper for sample efficiency.

---

## 3. Hierarchical Convergence & Deep Reasoning

### 3.1 Limitations of Standard Deep Transformers

Standard 48â€“72-layer transformers exhibit:

- **Vanishing gradients** across depth.
- **Attention collapse** leading to under-utilized later layers.
- **Fixed depth ceiling** â€” they cannot dynamically deepen reasoning effectively.

### 3.2 HEARTâ€™s Segmented Recursion with Detached Gradients

**Training organized into supervision segments:**

```text
For each (x, y) pair:
  1. Run one segment with L/H updates + base LM.
  2. Compute losses (LM cross-entropy, alignment, epistemic classification).
  3. DETACH final L/H states from the graph.
  4. Use detached states as initialization for next segment.
  5. Repeat for S segments.
```

**Why DETACH is crucial:**

- No backprop-through-time over full SÃ—CÃ—R depth.
- Gradients flow only within each segment â†’ stable training.
- Fresh detached initializations prevent representational collapse.
- Memory is **O(1)** in S (supervision segments).

### 3.3 Effective Depth

```text
D_eff = S Ã— C Ã— R Ã— d_LM

where:
  S    = supervision segments (e.g., 4â€“6)
  C    = cycles per segment (e.g., 2â€“3)
  R    = steps per cycle (e.g., 2â€“4)
  d_LM = effective depth of base LM per step (e.g., 3â€“6)
```

**Example configs:**

- **Conservative:** S=4, C=2, R=2, d_LM=3 â†’ D_eff = 48
- **Aggressive:** S=7, C=3, R=2, d_LM=2 â†’ D_eff = 84
- **Massive:** S=6, C=4, R=3, d_LM=3 â†’ D_eff = 216 (with stability gating)

### 3.4 PACâ€‘Bayes Hallucination Risk Bound (Sketch)

We derive a PACâ€‘Bayes bound of the form:

```text
R_halluc(Q) â‰¤ RÌ‚_halluc(Q)
              + âˆš{ [KL(Q || P) + log(1/Î´)] / (2m) } Ã— g(D_eff, á¾±)

where:  g(D_eff, á¾±) = C Â· exp(-Î» Â· D_eff Â· á¾±)
```

- **R_halluc(Q)**: True hallucination risk under posterior Q.
- **RÌ‚_halluc(Q)**: Empirical hallucination risk.
- **á¾±**: Average alignment score.
- **g(Â·)** decays *exponentially* in D_effÂ·á¾±.

**Implication:**
More effective depth (with maintained alignment) â†’ exponentially lower hallucination risk.

Empirically, correlation between bound and observed error is high (Ï > 0.85).

---

## 4. Modified GPTâ€‘2: Endâ€‘toâ€‘End Flow

### 4.1 Standard GPTâ€‘2

```text
Input x â†’ [Transformer Blocks] â†’ Logits â†’ Softmax â†’ Next Token
```

### 4.2 HEARTâ€‘Enhanced GPTâ€‘2

```text
Input x
  â†“
[Segment 1]
  h_Lâ° â† init
  FOR t = 1..T:
    Ï†(x, yâ‚:â‚œâ‚‹â‚) = GPTâ€‘2 encode
    h_Láµ— = f_L(h_Láµ—â»Â¹, h_Há¶œ, Ï†(Â·))
    y_t  = GPTâ€‘2 decode with h_Láµ— context
    (Î±â‚œ, Ï€â‚œ) = Validator(h_Láµ—, logits, attentions, SAE features)

    if Ï€â‚œ(abstain) > Ï„_a:
      return "I'm not confident about this."

    if Ï€â‚œ(retrieve) > Ï„_r:
      perform targeted RAG â†’ augment context

    if Ï€â‚œ(repair) > Ï„_p:
      trigger local/self-correction

    else:
      commit y_t to output

  hÌƒ_Lá¶œ = converged Lâ€‘state
  DETACH(hÌƒ_Lá¶œ)
  h_Há¶œâºÂ¹ = f_H(h_Há¶œ, hÌƒ_Lá¶œ)
  DETACH(h_Há¶œâºÂ¹)
  â†“
[Segments 2..S]  (repeat)
  â†“
Output sequence + epistemic trace
```

**Error Correction Pathways:**

- **Local (Lâ€‘module):**
  Short-range errors (e.g., grammar, small contradictions).

- **Global (Hâ€‘module):**
  Topic drift / long-range inconsistencies.

- **Validator Delegation:**
  Routes to retrieve/repair/abstain as necessary.

---

## 5. Parameter Efficiency

### 5.1 GPTâ€‘2 vs HEARTâ€‘Wrapped GPTâ€‘2 (Illustrative)

| Component       | GPTâ€‘2 Small | HEART Wrapper   | Total   | Reduction        |
|----------------|------------:|----------------:|--------:|------------------|
| Base LM        | 117M        | â€“               | 117M    | â€“                |
| Lâ€‘Module (Ã—S)  | â€“           | ~1M             | ~1M     | â€“                |
| Hâ€‘Module (Ã—S)  | â€“           | ~2M             | ~2M     | â€“                |
| Validator      | â€“           | ~5M             | ~5M     | â€“                |
| **Trainable**  | **117M**    | **8M**          | 125M    | **â‰ˆ93% â†“**       |

For more complex tasks (e.g., Sudokuâ€‘Extreme):

- 7B parameter GPTâ€‘2 baseline vs **8â€“15M** parameter HEART wrapper.
- **Trainable reduction:** up to **99.98%**
- **Performance:** 18.4% â†’ 68.9% (+50.5pp).

---

## 6. HEARTâ€‘CL: Continual Learning at Inference

### 6.1 Idea

HEARTâ€‘CL updates the wrapper during deployment with **strong safety gates**.

**Online adaptation loop:**

```text
1. Run standard HEART inference.
2. Log:
   - Repair events,
   - Retrieval failures/successes,
   - (Optional) user corrections.
3. Compute adaptation loss:
   L_adapt = L_repair_success
           + Î»_c Â· L_consistency
           + Î»_r Â· L_retrieve_accuracy
4. Update with proximal regularization:
   Î¸_L_new = Î¸_L
             âˆ’ Î· âˆ‡L_adapt
             âˆ’ Î² âˆ‡D_KL(Î¸_L || Î¸_L_init)
   (Î· ~ 1eâ€‘6â€“1eâ€‘5; Î² > 0)
```

### 6.2 Safety Mechanisms

- **Validator Gating:**
  Update only when Î±â‚œ is high (e.g., > 0.8).

- **Domain Gating:**
  Disable updates entirely for highly sensitive domains (e.g., medical, legal).

- **Checkpoints & Rollback:**
  Regular snapshots; revert if metrics degrade.

- **EWCâ€‘style Penalty:**
  Penalize large deviations from initial parameters.

- **Full Audit Trail:**
  Log all adaptation events for later analysis.

### 6.3 Observed Gains

- **Domain shift robustness:** +8â€“12% on out-of-domain benchmarks.
- **User-specific adaptation:** +5â€“10% on personalization tasks.
- **No degradation** on held-out benchmarks when gates are set conservatively.

---

## 7. Experimental Results (Summary)

### 7.1 Hallucination Mitigation

| Benchmark  | Baseline LLM | Postâ€‘hoc Validator | HRM   | HEART | HEARTâ€‘CL |
|-----------:|-------------:|-------------------:|------:|------:|---------:|
| TruthfulQA | 42.3%        | 57.1%              | 58.9% | 72.8% | 75.2%    |
| HaluEval   | 58.2%        | 69.4%              | 71.3% | 84.7% | 86.1%    |
| CRAG       | 54.1%        | 65.8%              | 67.2% | 79.4% | 81.6%    |
| SimpleQA   | 28.4%        | 45.2%              | 46.9% | 68.3% | 70.1%    |

**Average improvement:**
- HEART: **+30.6pp**
- HEARTâ€‘CL: **+32.5pp**

### 7.2 Deep Reasoning

| Task        | Baseline | HRM   | HEART | Trainable Params |
|------------|---------:|------:|------:|-----------------:|
| Sudokuâ€‘Hard| 18.4%    | 52.7% | 68.9% | ~12M (99.98% â†“)  |
| Mazeâ€‘Hard  | 12.1%    | 41.3% | 55.8% | ~8M  (99.99% â†“)  |
| ARCâ€‘AGI    | 22.6%    | 39.2% | 51.8% | ~15M (99.97% â†“)  |

### 7.3 Safetyâ€‘Critical Tasks

| Domain            | Metric              | Baseline | HEART | Human Expert |
|------------------|---------------------|---------:|------:|------------:|
| Clinical QA       | Hallucination rate | 18.2%    | 4.3%  | 3.1%        |
| Clinical QA       | False positive rate| 12.4%    | 2.1%  | 1.8%        |
| Legal summarization | Factual error rate| 22.1%  | 5.8%  | 4.2%        |
| Legal summarization | Omission rate     | 9.3%   | 3.1%  | 2.0%        |

HEART can achieve **subâ€‘human error rates** on curated safety-critical datasets.

---

## 8. Validator Ablations

| Variant                        | TruthfulQA | HaluEval | Î” Avg vs Full |
|--------------------------------|-----------:|---------:|--------------:|
| Full HEART                     | 72.8%      | 84.7%    | â€”             |
| w/o Abstain                    | 68.3%      | 79.2%    | âˆ’5.0pp        |
| w/o Retrieve                   | 66.1%      | 77.3%    | âˆ’7.1pp        |
| w/o Repair                     | 69.4%      | 80.1%    | âˆ’4.0pp        |
| Scalar threshold (no policy)   | 65.2%      | 75.8%    | âˆ’8.3pp        |
| Static validator (no finetune) | 61.7%      | 71.2%    | âˆ’12.3pp       |

**Takeaway:** All four actions matter; **retrieve** gives the largest gains, and learned policies significantly outperform static thresholds.

---

## 9. Mechanistic Interpretability via SAE

HEART uses **Sparse Autoencoders (SAEs)** for concept-level features that drive validator decisions.

### 9.1 Causal Feature Circuits

- **Abstain features:**
  - Syntactic inconsistency detectors.
  - Named-entity conflict detectors.
  - Domain mismatch patterns.

- **Retrieve features:**
  - Unknown/rare concept detectors.
  - Knowledge-gap indicators (input vs generation divergence).
  - Low-confidence hypothesis signals.

- **Repair features:**
  - Contradiction detectors (negation vs affirmation).
  - Reasoning trajectory divergence.

### 9.2 Explained Variance

- Abstain features explain ~68% of abstain variance.
- Retrieve features explain ~71% of retrieve variance.
- Repair features explain ~65% of repair variance.

These results support that HEARTâ€™s epistemic behavior is driven by *interpretable, causal circuits*, not opaque heuristics.

---

## 10. Limitations & Mitigations

| Limitation                 | Impact                               | Mitigation                                      |
|---------------------------|--------------------------------------|-------------------------------------------------|
| Data bias & fairness      | Unfair / biased outputs              | Fairness-aware loss, adversarial augmentation   |
| Adversarial prompting     | Validator can be fooled              | Redâ€‘team training, adversarial examples         |
| Long symbolic proofs      | 30+ step proofs still challenging    | Hybrid neuroâ€‘symbolic systems with provers      |
| HEARTâ€‘CL instability      | Drift under online updates           | Strong gating, checkpoints, periodic resets     |
| Inference cost            | Extra cycles & retrieval add latency | Tune `S, C, R`; cache; disable HEARTâ€‘CL in prod |

---

## 11. Project Structure

```text
heart-of-ai/
â”œâ”€â”€ heart_model.py           # Core HEART architecture
â”œâ”€â”€ heart_validator.py       # Epistemic validator
â”œâ”€â”€ heart_sample.py          # Sampling and inference
â”œâ”€â”€ heart_train.py           # Training pipeline
â”œâ”€â”€ heart_main.py            # Main integration / API surface
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ heart-of-ai.png      # Architecture diagram
â”‚   â”œâ”€â”€ ALHAMDULILLAH_Heart_of_AI.pdf  # Research paper
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ heart_default.yaml   # Default configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md
```

---

## 12. Installation

### 12.1 Clone the repository

```bash
git clone https://github.com/cubzai/heart-of-ai.git
cd heart-of-ai
```

### 12.2 Create & activate virtual environment

```bash
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
```

### 12.3 Install dependencies

```bash
pip install -r requirements.txt
```

### 12.4 Preâ€‘download GPTâ€‘2 base model

```bash
python -c "from transformers import GPT2LMHeadModel, GPT2Tokenizer; \
GPT2LMHeadModel.from_pretrained('gpt2'); \
GPT2Tokenizer.from_pretrained('gpt2')"
```

### 12.5 Verify installation

```bash
python -c "from heart_main import HeartOfAI; \
heart = HeartOfAI(); \
print(heart.get_status())"
```

---

## 13. Quick Start

### 13.1 Basic inference with epistemic control

```python
from heart_main import HeartOfAI

# 1. Create HEART system in inference mode
heart = HeartOfAI(mode="inference")

# 2. Generate text with epistemic info
result = heart.generate(
    prompt="The future of AI is",
    max_length=100,
    temperature=0.7,
    return_epistemic_info=True,
)

print("Generated:", result["text"])
print("Epistemic path:", result["epistemic_info"]["epistemic_path"])
```

### 13.2 Interactive shell

```python
from heart_main import HeartOfAI

heart = HeartOfAI(mode="inference")
heart.interactive_mode()
```

### 13.3 HEARTâ€‘CL: adapt on feedback

```python
import tensorflow as tf
from heart_main import HeartOfAI

heart = HeartOfAI(mode="train")  # or dedicated adaptation mode

generated = tf.constant([1, 2, 3, 4, 5])
correct   = tf.constant([1, 2, 3, 4, 6])

heart.adapt_on_feedback(generated, correct)
```

---

## 14. Configuration Tuning

Default configuration: `config/heart_default.yaml`.

You can tune HEART for different regimes:

### 14.1 Accuracyâ€‘Focused (Hallucination Mitigation)

- `supervision_segments: 6â€“8`
- `cycles_per_segment: 3`
- `steps_per_cycle: 3`
- `alignment_weight: 0.7`
- `retrieve_threshold: 0.5`
- `temperature: 0.3`

### 14.2 Speedâ€‘Focused (Low Latency)

- `supervision_segments: 2â€“3`
- `cycles_per_segment: 1â€“2`
- `steps_per_cycle: 1â€“2`
- `temperature: 0.7`
- `top_k: 20`

### 14.3 Creativeâ€‘Focused (High Diversity)

- `temperature: 1.2`
- `top_p: 0.98`
- `top_k: 80`

### 14.4 Safetyâ€‘Critical (Medical, Legal)

- `enable_heart_cl: true` (optional with conservative gates)
- `alignment_weight: 0.8`
- `repair_max_iterations: 3`
- `retrieve_threshold: 0.4`

---

## 15. Benchmarking API

```python
from heart_main import HeartOfAI

heart = HeartOfAI()

# Evaluate hallucination robustness
hallucination_results = heart.evaluate_on_benchmark("hallucination", dataset)
print(f"Hallucination accuracy: {hallucination_results['accuracy']:.4f}")

# Evaluate reasoning depth / structure
reasoning_results = heart.evaluate_on_benchmark("reasoning", dataset)
print(f"Reasoning accuracy: {reasoning_results['accuracy']:.4f}")
```

> `dataset` format depends on your loader; see examples in the repo (if provided).

---

## 16. Deployment Checklist

Before deploying HEART in production:

### 16.1 Model Evaluation

- [ ] Run TruthfulQA, HaluEval, Sudoku, Maze, etc.
- [ ] Evaluate on your domain-specific datasets.
- [ ] Evaluate safety-critical tasks separately.
- [ ] Measure latency for realistic workloads.

### 16.2 Configuration

- [ ] Tune `(S, C, R)` for target accuracy/latency tradeoff.
- [ ] Set `retrieve_threshold`, `alignment_weight`, etc. conservatively.
- [ ] Configure HEARTâ€‘CL gates per domain.

### 16.3 Safety

- [ ] Redâ€‘team adversarial prompts.
- [ ] Evaluate robustness to distribution shifts.
- [ ] Validate calibration of Î± (alignment scores).
- [ ] Set up continuous monitoring for drift.

### 16.4 Integration

- [ ] Integrate with your data pipeline / API layer.
- [ ] Log all epistemic actions (accept/abstain/retrieve/repair).
- [ ] Set alerts for high abstain or repair rates.
- [ ] Implement rollback / killâ€‘switch.

### 16.5 Documentation

- [ ] Model card (capabilities, limitations, failure modes).
- [ ] API documentation & examples.
- [ ] Deployment runbook.
- [ ] Monitoring and onâ€‘call procedures.

### 16.6 Monitoring

- [ ] Track accuracy and hallucination rate over time.
- [ ] Monitor abstain / retrieve / repair rates.
- [ ] Track repair effectiveness.
- [ ] Log all epistemic decisions for audits.

---

## 17. Troubleshooting

Common issues & fixes:

- **Out of memory (OOM)**
  - Reduce `batch_size`.
  - Lower `supervision_segments` or repair steps.
  - Enable gradient checkpointing.
  - Use mixed precision (`fp16`).

- **Low accuracy**
  - Increase `supervision_segments`.
  - Increase `alignment_weight`.
  - Lower `retrieve_threshold`.
  - Increase training epochs and validator data quality.

- **High latency**
  - Reduce `supervision_segments`.
  - Reduce `steps_per_cycle`.
  - Increase `temperature` and narrow search (`top_k`).
  - Disable HEARTâ€‘CL during inference.

- **Model keeps abstaining**
  - Lower `alignment_weight`.
  - Increase `retrieve_threshold`.
  - Train validator more / better data.
  - Check for domain mismatch.

- **HEARTâ€‘CL not improving**
  - Ensure very low learning rate (â‰¤ 1eâ€‘6).
  - Check feedback quality and label noise.
  - Enable consistency loss.
  - Adjust adaptation frequency and gating thresholds.

---

## 18. References & Citation

If you use HEART in research or production, please cite:

```bibtex
@article{aslam2025heart,
  title={HEART: Hierarchical Epistemic Architecture for Reasoning and Truth-seeking},
  author={Aslam, Anees and Aslam, Thabassum},
  year={2025},
  organization={CubzAI}
}
```

Related work:

- Radford et al. (2019) â€” GPTâ€‘2.
- Wang et al. (2025) â€” Hierarchical Recursive Models.
- Cunningham et al. (2023) â€” Sparse Autoencoders.
- Lewis et al. (2021) â€” Retrieval-Augmented Generation (RAG).

---

## 19. Contact & Support

- **GitHub:** https://github.com/cubzai/heart-of-ai
- **Email:** [`cubzai.labs@gmail.com`](mailto:cubzai.labs@gmail.com)

Community:

- Discussions: https://github.com/cubzai/heart-of-ai/discussions
- Issues: https://github.com/cubzai/heart-of-ai/issues
- Twitter / X: **@CubzAI**

Contributions are welcome â€” please see `CONTRIBUTING.md` (if present) or open an Issue/Discussion first for large changes.

---

## 20. License

HEART is released under a **Modified MIT License**.
See the `LICENSE` file for full terms.

> Note: The base GPTâ€‘2 model is from OpenAI and subject to its own license terms and acceptable use policies.

---

## 21. Quick CLI Reminder

```bash
python heart_main.py
```

```text
HEART Installation and Setup Guide
======================================================================
Run: pip install -r requirements.txt
Then: python heart_main.py
======================================================================
```
